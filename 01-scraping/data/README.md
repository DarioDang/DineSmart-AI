# ğŸ“ Data Directory â€” Structure & Purpose

This directory stores all datasets generated during the restaurant scraping pipeline, including raw extracted data, cleaned and merged datasets, enriched outputs, and example files used for debugging.

The folder is organized into logical layers to ensure clarity, reproducibility, and compatibility with downstream components (Qdrant indexing, Streamlit Agent, Phoenix evaluations, etc.).

## ğŸ“‚ Folder Breakdown

```
data/
â”‚
â”œâ”€â”€ yelp-data/
â”‚   â”œâ”€â”€ chc-yelps-reviews-data/
â”‚   â”‚   â”œâ”€â”€ chc-yelp-place-ids-reviews.parquet
â”‚   â”‚   â”œâ”€â”€ chc-yelp-place-ids.json
â”‚   â”‚   â””â”€â”€ christchurch-reviews-all-pages.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ final-dataset/
â”‚   â”‚   â”œâ”€â”€ chc-yelp-place-ids.json
â”‚   â”‚   â”œâ”€â”€ chc-yelp-reviews.json
â”‚   â”‚   â”œâ”€â”€ chc-yelp-reviews.parquet
â”‚   â”‚   â””â”€â”€ chc-yelp-reviews.csv
â”‚   â”‚
â”‚   â””â”€â”€ README.md (optional)
â”‚
â”œâ”€â”€ google-data/
â”‚   â”œâ”€â”€ google-restaurants-place/
â”‚   â”‚   â””â”€â”€ chc_google_places.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ google-reviews/
â”‚   â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”‚   â”œâ”€â”€ chc_reviews.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ chc_reviews.json
â”‚   â”‚   â”‚   â””â”€â”€ chc_reviews.parquet
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ final/
â”‚   â”‚       â”œâ”€â”€ chc-google-reviews.json
â”‚   â”‚       â””â”€â”€ chc-google-reviews.parquet
â”‚
â”œâ”€â”€ scraped-examples-data/
â”‚   â”œâ”€â”€ sample-yelp-review.json
â”‚   â””â”€â”€ sample-google-review.json
â”‚
â””â”€â”€ jupyter-notebook-experiments/
    â”œâ”€â”€ scrape-advanced-features-test.ipynb
    â”œâ”€â”€ scrape-google-reviews.ipynb
    â””â”€â”€ scrape-yelp-reviews.ipynb         
```

## ğŸ—‚ Folder Purpose Breakdown
### ğŸ“˜ Yelp Data
| Folder                              | Description                                                                  | Key Files                                                                                                       |
| ----------------------------------- | ---------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------- |
| `yelp-data/chc-yelps-reviews-data/` | Raw + flattened Yelp reviews scraped from SerpAPI                            | - `christchurch-reviews-all-pages.csv`<br>- `chc-yelp-place-ids.json`<br>- `chc-yelp-place-ids-reviews.parquet` |
| `yelp-data/final-dataset/`          | Cleaned, merged, and final Yelp datasets used for downstream ingestion & RAG | - `chc-yelp-reviews.json`<br>- `chc-yelp-reviews.parquet`<br>- `chc-yelp-reviews.csv`                           |
| (optional) README.md                | Explains Yelp scraping lineage                                               | â€”                                                                                                               |

### ğŸ“— Google Data
| Folder                      | Description                                                         | Key Files                                                              |
| --------------------------- | ------------------------------------------------------------------- | ---------------------------------------------------------------------- |
| `google-restaurants-place/` | Google Places metadata (IDs, names, addresses)                      | - `chc_google_places.csv`                                              |
| `google-reviews/raw/`       | Raw exported reviews directly from the scraper                      | - `chc_reviews.csv`<br>- `chc_reviews.json`<br>- `chc_reviews.parquet` |
| `google-reviews/final/`     | Cleaned + processed datasets ready for model ingestion or S3 upload | - `chc-google-reviews.json`<br>- `chc-google-reviews.parquet`          |

### ğŸ§ª Examples & Notebooks
| Folder                          | Purpose                                                                                                                        |
| ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| `scraped-examples-data/`        | Minimal example review files used for debugging pipeline steps                                                                 |
| `jupyter-notebook-experiments/` | Notebooks used to prototype scrapers, validate review extraction, test feature enhancement (e.g., cuisine tagging, embeddings) |


### ğŸ¯ Usage in the Pipeline

| Stage            | Input Folder            | Output Folder                       |
| ---------------- | ----------------------- | ----------------------------------- |
| Scrape place_ids | â€”                       | `yelp-data/chc-yelps-reviews-data/` |
| Scrape reviews   | Yelp/Google raw folders | Same folder (raw JSON + CSV)        |
| Clean & merge    | Raw folders             | `final-dataset/` or `final/`        |
| Enrich features  | Final datasets          | Qdrant-ready vectors or metadata    |
| Upload to S3     | Final datasets          | `dario-ai-agent-reviews` bucket     |


## ğŸ“ Notes

Large datasets should not be committed to GitHub.

Parquet is the preferred format for downstream use.

All review timestamps should be normalized before ingestion.

## Author

Dario Dang

Applied Data Scientist | MLOps & Data Engineering Enthusiast

